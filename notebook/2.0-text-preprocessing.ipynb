{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegexRemover(TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        self.patterns = [\n",
    "            r\"[^\\w\\s]|_\",  # Remove all special characters / punctuations\n",
    "            r\"\\d+\",  # Remove all numbers\n",
    "            r\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U00002639\\U0000263A]+\",  # Remove all emoji / emoticon\n",
    "        ]\n",
    "\n",
    "    def remove_patterns(self, text: str) -> str:\n",
    "        for pattern in self.patterns:\n",
    "            text = re.sub(pattern, \"\", text)\n",
    "        return text\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        df_pre = df.copy()\n",
    "        df_pre.loc[:, \"comment\"] = df_pre[\"comment\"].apply(self.remove_patterns)\n",
    "        return df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordRemover(TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        self.stop_word_remover = StopWordRemoverFactory().create_stop_word_remover()\n",
    "        self.stop_word_remover.get_dictionary().add(\"nya\")\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        df_pre = df.copy()\n",
    "        df_pre.loc[:, \"comment\"] = df_pre[\"comment\"].apply(\n",
    "            self.stop_word_remover.remove\n",
    "        )\n",
    "        return df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer(TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        self.stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        df_pre = df.copy()\n",
    "        df_pre.loc[:, \"comment\"] = df_pre[\"comment\"].apply(self.stemmer.stem)\n",
    "        return df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_strip(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_pre = df.copy()\n",
    "    df_pre.loc[:, \"comment\"] = df_pre[\"comment\"].apply(lambda x: x.lower().strip())\n",
    "\n",
    "    return df_pre\n",
    "\n",
    "\n",
    "def remove_one_letter(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_pre = df.copy()\n",
    "\n",
    "    def _remove_one_letter(text: str):\n",
    "        words = text.split(\" \")\n",
    "        for word in words:\n",
    "            if len(word) == 1:\n",
    "                words.remove(word)\n",
    "\n",
    "        return \" \".join(words)\n",
    "\n",
    "    df_pre.loc[:, \"comment\"] = df_pre[\"comment\"].apply(_remove_one_letter)\n",
    "\n",
    "    return df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"lower_case_strip\", FunctionTransformer(func=to_lower_strip)),\n",
    "        (\"regex_remover\", RegexRemover()),\n",
    "        (\"stop_word_remover\", StopWordRemover()),\n",
    "        (\"stemmer\", Stemmer()),\n",
    "        (\"remove_one_letter\", FunctionTransformer(func=remove_one_letter)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/tokopedia_tws_f9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barang sih oktp yaa kemas bagi dalam yg rusak bolong utk sellernya perhati kemas dalam meski barang oke dalam k'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc[93][\"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
